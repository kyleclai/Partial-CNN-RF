{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d6d64dc",
   "metadata": {},
   "source": [
    "### Cell 1: Imports\n",
    "This cell contains all the necessary libraries. We're adding RandomForestClassifier and pickle for saving/loading the layer outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfad3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import subprocess\n",
    "import gc\n",
    "import pickle  # Added for saving/loading layer outputs\n",
    "import tensorflow as tf\n",
    "import cv2 # OpenCV for robust image loading/resizing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras import layers, models, backend as K # ‚¨ÖÔ∏è THIS LINE IS FIXED\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # ‚¨ÖÔ∏è NEW: Import Random Forest\n",
    "from tensorflow.keras.models import Model # ‚¨ÖÔ∏è NEW: For creating feature extractors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec74ab6",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "This cell holds all your global constants. This makes it easy to tweak your experiment (e.g., change IMG_HEIGHT, BATCH_SIZE, or N_FOLDS) without digging through the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6768e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "BASE_DATA_DIR       = \"../00_download_dataset/dogs-vs-cats\"\n",
    "TRAIN_DATA_DIR      = os.path.join(BASE_DATA_DIR, \"train\")\n",
    "CSV_METADATA_FILE   = os.path.join(BASE_DATA_DIR, \"train_metadata.csv\")\n",
    "RESULTS_DIR         = \"./results\" # ‚¨ÖÔ∏è NEW: A dedicated folder for results\n",
    "RESULTS_CSV_PATH    = os.path.join(RESULTS_DIR, \"hybrid_cnn_rf_kfold_results.csv\")\n",
    "ACTIVATION_PKL_PATH = os.path.join(RESULTS_DIR, \"last_fold_activations.pkl\")\n",
    "\n",
    "\n",
    "IMG_HEIGHT          = 128 # 128 # 250\n",
    "IMG_WIDTH           = 128 # 250\n",
    "# CRITICAL: Batch size of 12 is good for 250x250 images on a single GPU\n",
    "BATCH_SIZE          = 12 \n",
    "RANDOM_STATE        = 42\n",
    "MAX_SAMPLES_PER_CLASS = 5000 # 5000 # 22000\n",
    "NUM_CLASSES         = 2 \n",
    "N_FOLDS             = 5\n",
    "EPOCHS              = 20 # ‚¨ÖÔ∏è NEW: Define epochs here for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94612722",
   "metadata": {},
   "source": [
    "### GPU & Memory Management\n",
    "These are your helper functions to manage system resources, especially for TensorFlow. Running setup_tensorflow_memory() early is good practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c71bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_available_gpus():\n",
    "    # ... (Your original code)\n",
    "    physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"Num GPUs Available: {len(physical_gpus)}\")\n",
    "    for gpu in physical_gpus:\n",
    "        print(f\"  {gpu}\")\n",
    "\n",
    "def setup_tensorflow_memory(force_cpu=False):\n",
    "    \"\"\"\n",
    "    MODIFIED: This function now targets a SINGLE GPU (GPU:1)\n",
    "    to simplify resource management.\n",
    "    \"\"\"\n",
    "    physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "    \n",
    "    if force_cpu:\n",
    "        print(\"üñ•Ô∏è Forcing CPU-only mode...\")\n",
    "        tf.config.set_visible_devices([], 'GPU')\n",
    "        print(\"‚úÖ CPU-only mode enabled\")\n",
    "        return\n",
    "\n",
    "    # ‚¨áÔ∏è --- THIS IS THE MODIFICATION --- ‚¨áÔ∏è\n",
    "    # We will target *only* GPU:1.\n",
    "    # Change the index [1] if you want to use GPU:2 or GPU:3 instead.\n",
    "    TARGET_GPU_INDEX = 1 \n",
    "    \n",
    "    if physical_gpus and len(physical_gpus) > TARGET_GPU_INDEX:\n",
    "        \n",
    "        # Select ONLY the target GPU\n",
    "        gpus_to_configure = [physical_gpus[TARGET_GPU_INDEX]]\n",
    "        \n",
    "        # Tell TensorFlow to make *only* this GPU visible\n",
    "        tf.config.set_visible_devices(gpus_to_configure, 'GPU')\n",
    "        \n",
    "        print(f\"üéØ Configuring ONLY Physical GPU {TARGET_GPU_INDEX}.\")\n",
    "    # ‚¨ÜÔ∏è --- END OF MODIFICATION --- ‚¨ÜÔ∏è\n",
    "    \n",
    "    else:\n",
    "        # Fallback in case GPU:1 isn't found\n",
    "        gpus_to_configure = physical_gpus\n",
    "        print(f\"‚ö†Ô∏è Could not find GPU {TARGET_GPU_INDEX}. Configuring all available GPUs.\")\n",
    "\n",
    "    if not gpus_to_configure:\n",
    "        print(\"‚ùå No GPUs detected. Using CPU.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Apply memory growth to our selected GPU\n",
    "        for gpu in gpus_to_configure:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        tf.config.optimizer.set_jit(True) \n",
    "        print(\"‚ö° XLA optimization enabled.\")\n",
    "        \n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"‚úÖ Successfully configured {len(logical_gpus)} logical GPU(s).\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ùå GPU configuration error: {e}\")\n",
    "\n",
    "def aggressive_memory_cleanup():\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    time.sleep(0.5)\n",
    "    print(\"üßπ Aggressive memory cleanup completed\")\n",
    "    \n",
    "\n",
    "# --- Setup Memory ---\n",
    "# Create results dir\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Run the NEW GPU setup\n",
    "setup_tensorflow_memory()\n",
    "list_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d10f9",
   "metadata": {},
   "source": [
    "### Data Loading Helpers\n",
    "These functions are responsible for loading your entire dataset from disk into two large NumPy arrays in RAM. This \"in-memory\" approach is fast for training after the initial load, but requires a lot of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metadata():\n",
    "    \"\"\"Reads or creates the metadata CSV and returns the filtered DataFrame.\"\"\"\n",
    "    if not os.path.exists(CSV_METADATA_FILE):\n",
    "        # ... (Your original 2.1 CSV creation logic must be here) ...\n",
    "        print(f\"Error: {CSV_METADATA_FILE} not found!\")\n",
    "        print(\"Please run your dataset download/prep script first.\")\n",
    "        return None, None\n",
    "         \n",
    "    df = pd.read_csv(CSV_METADATA_FILE)\n",
    "\n",
    "    # Apply sample limit (Original 2.2 logic)\n",
    "    if MAX_SAMPLES_PER_CLASS is not None:\n",
    "        df = df.groupby('class').apply(\n",
    "            lambda x: x.sample(min(len(x), MAX_SAMPLES_PER_CLASS), random_state=RANDOM_STATE)\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    # Create label mapping\n",
    "    labels_text_all = df[\"class\"].values\n",
    "    unique_labels_sorted = sorted(list(set(labels_text_all)))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels_sorted)}\n",
    "    index_to_label = {idx: label for label, idx in label_to_index.items()} # ‚¨ÖÔ∏è NEW: Good for plots\n",
    "    \n",
    "    df['label_numeric'] = df['class'].map(label_to_index)\n",
    "    \n",
    "    print(f\"Metadata prepared: {len(df)} samples.\")\n",
    "    print(f\"Label map: {label_to_index}\")\n",
    "    \n",
    "    return df, label_to_index, index_to_label\n",
    "\n",
    "\n",
    "def dataloader_catdog_numpy(df):\n",
    "    \"\"\"\n",
    "    Loads all Cats vs. Dogs images into RAM, resizing and normalizing them.\n",
    "    \"\"\"\n",
    "    print(f\"‚è±Ô∏è Starting image load/resize for {len(df)} samples into RAM...\")\n",
    "    x, y = [], []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            img = cv2.imread(row['path']) \n",
    "            if img is None:\n",
    "                raise Exception(f\"Could not read image {row['path']}\")\n",
    "                \n",
    "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "            img = img.astype(np.float32) / 255.0      # Normalize\n",
    "            \n",
    "            x.append(img)\n",
    "            y.append(row['label_numeric'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {e}. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "    print(f\"‚úÖ Data loaded into RAM: {len(x)} samples.\")\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e4fe6",
   "metadata": {},
   "source": [
    "### Plotting & Activation Helpers\n",
    "These are your utility functions.\n",
    "\n",
    "The `plot_*` functions are for evaluating model performance at the end of a fold.\n",
    "\n",
    "`get_all_layer_outputs` is your function to grab activations from all layers, which we'll use for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a8405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, fold_num):\n",
    "    \"\"\"Plots the training loss and accuracy over epochs.\"\"\"\n",
    "    print(f\"\\nüìà Plotting Training History for Fold {fold_num}...\")\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot Loss\n",
    "    ax1.plot(history.history['loss'], color='b', label=\"Training Loss\")\n",
    "    ax1.set_title(f\"Fold {fold_num} - Training Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot Accuracy\n",
    "    ax2.plot(history.history['accuracy'], color='g', label=\"Training Accuracy\")\n",
    "    ax2.set_title(f\"Fold {fold_num} - Training Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Generates and plots a Confusion Matrix.\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt=\"d\", \n",
    "        cmap=\"Blues\", \n",
    "        xticklabels=labels, \n",
    "        yticklabels=labels\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba):\n",
    "    \"\"\"Calculates and plots the Receiver Operating Characteristic (ROC) curve.\"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def get_all_layer_outputs(model, x_data, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extracts and returns the outputs from every layer in a Keras model.\n",
    "    Used for visualization.\n",
    "    Returns a dict mapping layer names to their activation tensors (numpy arrays).\n",
    "    \"\"\"\n",
    "    print(f\"Extracting all layer outputs for {len(x_data)} samples...\")\n",
    "    \n",
    "    # Collect all layer outputs (skip the Input layer)\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'input' not in layer.name.lower()]\n",
    "    layer_names = [layer.name for layer in model.layers if 'input' not in layer.name.lower()]\n",
    "    \n",
    "    # Create a new model that returns all those outputs\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Run inference on the input data\n",
    "    activations = activation_model.predict(x_data, batch_size=batch_size, verbose=1)\n",
    "    \n",
    "    # Handle single-layer case\n",
    "    if len(layer_names) == 1:\n",
    "        activations = [activations]\n",
    "        \n",
    "    # Package into a dictionary: {layer_name: activations}\n",
    "    layer_output_dict = {}\n",
    "    for name, act in zip(layer_names, activations):\n",
    "        layer_output_dict[name] = act\n",
    "        print(f\"  -> Extracted {name:20s} | Shape: {act.shape}\")\n",
    "    \n",
    "    return layer_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962c151",
   "metadata": {},
   "source": [
    "### CNN & Hybrid Model Helpers\n",
    "This is where we define the models.\n",
    "\n",
    "1. `build_cnn_model`: Your original function to create the full LeNet.\n",
    "\n",
    "2. `create_feature_extractor`: (NEW) A crucial helper that takes a trained CNN and a layer name, then \"chops off\" the top and returns a new model that just outputs that layer's features.\n",
    "\n",
    "3. `run_hybrid_rf_experiment`: (NEW) This function takes the data and one of the new extractor models, generates the features, flattens them, and runs the full RF train/test experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ad07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds the LeNet-style CNN model using the stable Functional API approach.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    \n",
    "    # Layer C1: Conv(6) -> Pool(2x2)\n",
    "    # We add 'name' so we can easily target it later\n",
    "    x = layers.Conv2D(6, (5, 5), activation='relu', name='conv_1')(x) \n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), name='pool_1')(x)\n",
    "    \n",
    "    # Layer C2: Conv(16) -> Pool(2x2)\n",
    "    x = layers.Conv2D(16, (5, 5), activation='relu', name='conv_2')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2), name='pool_2')(x)\n",
    "    \n",
    "    # Flatten: Feature Vector\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    \n",
    "    # Dense Layers (C5, F6)\n",
    "    x = layers.Dense(120, activation='relu', name='dense_1')(x)\n",
    "    x = layers.Dense(84, activation='relu', name='dense_2')(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = layers.Dense(1, activation='sigmoid', name='output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def create_feature_extractor(full_trained_model, layer_name):\n",
    "    \"\"\"\n",
    "    Takes a fully trained Keras model and the name of an intermediate\n",
    "    layer, and returns a NEW model that outputs that layer's activations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new model that shares the same inputs as the\n",
    "        # original, but outputs the activations from the desired layer.\n",
    "        extractor_model = Model(\n",
    "            inputs=full_trained_model.input,\n",
    "            outputs=full_trained_model.get_layer(layer_name).output\n",
    "        )\n",
    "        return extractor_model\n",
    "    except ValueError as e:\n",
    "        print(f\"Error creating extractor for layer '{layer_name}': {e}\")\n",
    "        print(\"Check your model's layer names with model.summary()\")\n",
    "        return None\n",
    "\n",
    "def run_hybrid_rf_experiment(extractor_model, x_train, y_train, x_test, y_test, batch_size):\n",
    "    \"\"\"\n",
    "    Uses a feature_extractor model to generate features, then\n",
    "    trains and evaluates a Random Forest on them.\n",
    "    \"\"\"\n",
    "    layer_name = extractor_model.output.name.split('/')[0] # Get clean layer name\n",
    "    print(f\"--- üå≥ Starting Hybrid RF Experiment for layer: {layer_name} ---\")\n",
    "    \n",
    "    # 1. Generate features\n",
    "    print(f\"Generating features for {x_train.shape[0]} train samples...\")\n",
    "    start_feat_time = time.time()\n",
    "    x_train_features = extractor_model.predict(x_train, batch_size=batch_size, verbose=1)\n",
    "    print(f\"Generating features for {x_test.shape[0]} test samples...\")\n",
    "    x_test_features = extractor_model.predict(x_test, batch_size=batch_size, verbose=1)\n",
    "    feat_gen_time = time.time() - start_feat_time\n",
    "    print(f\"Feature generation took {feat_gen_time:.2f}s\")\n",
    "\n",
    "    # 2. Flatten features\n",
    "    # RF needs 2D input: (n_samples, n_features)\n",
    "    # Conv layers output 4D: (n_samples, H, W, C)\n",
    "    print(f\"Original feature shape: {x_train_features.shape}\")\n",
    "    if x_train_features.ndim > 2:\n",
    "        # Reshape (e.g., 35200, 59, 59, 16) -> (35200, 59*59*16)\n",
    "        n_samples_train = x_train_features.shape[0]\n",
    "        n_samples_test = x_test_features.shape[0]\n",
    "        \n",
    "        x_train_features_flat = x_train_features.reshape(n_samples_train, -1)\n",
    "        x_test_features_flat = x_test_features.reshape(n_samples_test, -1)\n",
    "    else:\n",
    "        x_train_features_flat = x_train_features\n",
    "        x_test_features_flat = x_test_features\n",
    "        \n",
    "    print(f\"Flattened feature shape: {x_train_features_flat.shape}\")\n",
    "\n",
    "    # 3. Train Random Forest\n",
    "    print(\"Training Random Forest...\")\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100, # A good, fast default\n",
    "        random_state=RANDOM_STATE, \n",
    "        n_jobs=-1 # Use all available CPU cores\n",
    "    )\n",
    "    start_rf_train = time.time()\n",
    "    rf_model.fit(x_train_features_flat, y_train)\n",
    "    rf_train_time = time.time() - start_rf_train\n",
    "    print(f\"RF training took {rf_train_time:.2f}s\")\n",
    "    \n",
    "    # 4. Evaluate Random Forest\n",
    "    y_pred_rf = rf_model.predict(x_test_features_flat)\n",
    "    \n",
    "    # 5. Calculate metrics\n",
    "    metrics = {\n",
    "        'model_name': f'RF_from_{layer_name}',\n",
    "        'accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "        'precision': precision_score(y_test, y_pred_rf, average='binary', zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred_rf, average='binary', zero_division=0),\n",
    "        'f1_score': f1_score(y_test, y_pred_rf, average='binary', zero_division=0),\n",
    "        'train_time': rf_train_time,\n",
    "        'feature_gen_time': feat_gen_time\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ RF from {layer_name} Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf0fe58",
   "metadata": {},
   "source": [
    "### Main K-Fold Runner (The \"Orchestrator\")\n",
    "This is the most important cell. It's your original `standard_cnn_runner`, but heavily modified to run the new hybrid experiments inside the K-Fold loop.\n",
    "\n",
    "Read the comments to see the flow:\n",
    "\n",
    "1. Train Baseline CNN (Model A).\n",
    "\n",
    "2. Get Baseline CNN metrics.\n",
    "\n",
    "3. Define which layers to extract from.\n",
    "\n",
    "4. Loop through each layer, create an extractor, and run the RF experiment (Model B, C, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cnn_rf_runner(df, label_map, n=N_FOLDS, epochs=EPOCHS, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    MODIFIED: Runs K-Fold Cross-Validation for BOTH the standard\n",
    "    CNN and the hybrid CNN-RF models.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Starting Hybrid CNN-RF K-Fold Runner...\")\n",
    "    \n",
    "    # Load all data into NumPy arrays\n",
    "    x, y = dataloader_catdog_numpy(df)\n",
    "    \n",
    "    print(f\"üìà Total samples loaded: {x.shape[0]}. Input shape: {x.shape[1:]}\")\n",
    "    input_shape = x.shape[1:]\n",
    "    \n",
    "    # This is the list of layers you want to test\n",
    "    # We use the names we defined in build_cnn_model\n",
    "    # We test every major feature-processing step\n",
    "    LAYERS_TO_EXTRACT_FROM = [\n",
    "        'conv_1',  # After 1st Conv\n",
    "        'pool_1',  # After 1st Pool\n",
    "        'conv_2',  # After 2nd Conv\n",
    "        'pool_2',  # After 2nd Pool\n",
    "        'flatten', # After Flatten\n",
    "        'dense_1', # After 1st Dense\n",
    "        'dense_2'  # After 2nd Dense\n",
    "    ]\n",
    "    \n",
    "    all_results_list = []\n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üîÑ Starting Fold {fold + 1}/{n}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        aggressive_memory_cleanup()\n",
    "        \n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        print(f\"üìä Fold {fold + 1} - Train: {x_train.shape[0]}, Test: {x_test.shape[0]}\")\n",
    "        \n",
    "        # =======================================================\n",
    "        # 1. TRAIN BASELINE CNN (MODEL A)\n",
    "        # =======================================================\n",
    "        print(\"\\n--- üß† Training Baseline CNN (Model A) ---\")\n",
    "        start_cnn_train = time.time()\n",
    "        \n",
    "        # Build and compile the model\n",
    "        baseline_model = build_cnn_model(input_shape)\n",
    "        baseline_model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Print a summary on the first fold to see layer names\n",
    "        if fold == 0:\n",
    "            print(baseline_model.summary())\n",
    "\n",
    "        # Fit the model\n",
    "        history = baseline_model.fit(\n",
    "            x_train, y_train, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            verbose=1,\n",
    "            validation_data=None # We use the test set for final eval\n",
    "        )\n",
    "        \n",
    "        cnn_train_time = time.time() - start_cnn_train\n",
    "        print(f\"‚è±Ô∏è CNN training completed in {cnn_train_time:.2f} seconds\")\n",
    "\n",
    "        # Evaluate the CNN\n",
    "        y_pred_cnn_proba = baseline_model.predict(x_test, batch_size=batch_size, verbose=0).flatten()\n",
    "        y_pred_cnn_binary = (y_pred_cnn_proba > 0.5).astype(int)\n",
    "\n",
    "        # Store CNN metrics\n",
    "        cnn_metrics = {\n",
    "            'model_name': 'Full_CNN (Baseline)',\n",
    "            'run': fold + 1,\n",
    "            'accuracy': accuracy_score(y_test, y_pred_cnn_binary),\n",
    "            'precision': precision_score(y_test, y_pred_cnn_binary, average='binary', zero_division=0),\n",
    "            'recall': recall_score(y_test, y_pred_cnn_binary, average='binary', zero_division=0),\n",
    "            'f1_score': f1_score(y_test, y_pred_cnn_binary, average='binary', zero_division=0),\n",
    "            'train_time': cnn_train_time\n",
    "        }\n",
    "        all_results_list.append(cnn_metrics)\n",
    "        print(f\"‚úÖ Baseline CNN Accuracy: {cnn_metrics['accuracy']:.4f}\")\n",
    "        \n",
    "        \n",
    "        # =======================================================\n",
    "        # 2. RUN HYBRID RF EXPERIMENTS (MODELS B, C, ...)\n",
    "        # =======================================================\n",
    "        print(f\"\\n--- üå≥ Starting Hybrid RF Experiments (Models B, C, ...) ---\")\n",
    "        \n",
    "        for layer_name in LAYERS_TO_EXTRACT_FROM:\n",
    "            aggressive_memory_cleanup()\n",
    "            \n",
    "            # Create a new extractor model from the *trained* baseline model\n",
    "            extractor = create_feature_extractor(baseline_model, layer_name)\n",
    "            \n",
    "            if extractor:\n",
    "                # Run the full RF experiment\n",
    "                rf_metrics = run_hybrid_rf_experiment(\n",
    "                    extractor_model=extractor,\n",
    "                    x_train=x_train,\n",
    "                    y_train=y_train,\n",
    "                    x_test=x_test,\n",
    "                    y_test=y_test,\n",
    "                    batch_size=batch_size\n",
    "                )\n",
    "                rf_metrics['run'] = fold + 1\n",
    "                all_results_list.append(rf_metrics)\n",
    "\n",
    "        \n",
    "        # =======================================================\n",
    "        # 3. PLOTTING & VISUALIZATION (FOR LAST FOLD ONLY)\n",
    "        # =======================================================\n",
    "        if fold == n - 1:\n",
    "            print(f\"\\n--- üìä Final Fold Visualizations ---\")\n",
    "            \n",
    "            # 1. Plot CNN Training History\n",
    "            plot_training_history(history, fold + 1)\n",
    "            \n",
    "            # 2. Plot CNN Confusion Matrix\n",
    "            target_names = [label_map[i] for i in range(len(label_map))]\n",
    "            plot_confusion_matrix(y_test, y_pred_cnn_binary, target_names, \n",
    "                                  title=f\"Baseline CNN Confusion Matrix (Fold {fold + 1})\")\n",
    "            \n",
    "            # 3. Plot CNN ROC Curve\n",
    "            plot_roc_curve(y_test, y_pred_cnn_proba)\n",
    "            \n",
    "            # 4. Save all layer activations AND inputs for ONE BATCH of test images\n",
    "            # This is for your interpretability goal\n",
    "            print(\"\\nSaving layer activations and inputs for visualization...\")\n",
    "            test_subset = x_test[:batch_size]\n",
    "            activation_dict = get_all_layer_outputs(baseline_model, test_subset, batch_size)\n",
    "            \n",
    "            # ‚¨áÔ∏è --- THIS IS THE MODIFICATION --- ‚¨áÔ∏è\n",
    "            data_to_save = {\n",
    "                'inputs': test_subset,\n",
    "                'activations': activation_dict\n",
    "            }\n",
    "            with open(ACTIVATION_PKL_PATH, \"wb\") as f:\n",
    "                pickle.dump(data_to_save, f)\n",
    "            # ‚¨ÜÔ∏è --- END OF MODIFICATION --- ‚¨ÜÔ∏è\n",
    "            \n",
    "            print(f\"üíæ Saved inputs and activations to {ACTIVATION_PKL_PATH}\")\n",
    "\n",
    "        # Clean up the baseline model to free memory\n",
    "        del baseline_model\n",
    "        del x_train, x_test, y_train, y_test\n",
    "        aggressive_memory_cleanup()\n",
    "        print(f\"üßπ Fold {fold + 1} cleanup completed\")\n",
    "\n",
    "    return all_results_list\n",
    "\n",
    "\n",
    "def main_pipeline(results_df_path=RESULTS_CSV_PATH):\n",
    "    \"\"\"\n",
    "    Main pipeline execution function.\n",
    "    \"\"\"\n",
    "    # 1. Get Metadata\n",
    "    df_metadata, label_to_index, index_to_label = prepare_metadata()\n",
    "    if df_metadata is None:\n",
    "        return\n",
    "    \n",
    "    # 2. Run the K-Fold Runner\n",
    "    all_results = standard_cnn_rf_runner(\n",
    "        df=df_metadata,\n",
    "        label_map=index_to_label,\n",
    "        n=N_FOLDS,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # 3. Save all results\n",
    "    if all_results:\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        results_df.to_csv(results_df_path, index=False)\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"üíæüèÜ All experiment results saved to {results_df_path}\")\n",
    "        print(f\"{'='*70}\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998eea8c",
   "metadata": {},
   "source": [
    "### üöÄ Run the Full Experiment\n",
    "This is the cell you'll execute to run the entire K-Fold cross-validation process. It will take a long time!\n",
    "\n",
    "Warning: This will train `1` (CNN) + `7` (RF models) = 8 models per fold. For 5 folds, this is 40 total models trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RUN THE EXPERIMENT ---\n",
    "\n",
    "print(\"Starting the full K-Fold pipeline...\")\n",
    "print(f\"This will run {N_FOLDS} folds.\")\n",
    "print(f\"Each fold trains 1 CNN ({EPOCHS} epochs) and {7} Random Forest models.\")\n",
    "print(\"This may take a significant amount of time.\")\n",
    "\n",
    "start_pipeline = time.time()\n",
    "\n",
    "final_results_df = main_pipeline(results_df_path=RESULTS_CSV_PATH)\n",
    "\n",
    "end_pipeline = time.time()\n",
    "print(f\"‚úÖ‚úÖ‚úÖ Full pipeline finished in {(end_pipeline - start_pipeline) / 60:.2f} minutes.\")\n",
    "\n",
    "# Display the head of the results\n",
    "if not final_results_df.empty:\n",
    "    print(final_results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264bd30",
   "metadata": {},
   "source": [
    "### üìä Analyze the Results\n",
    "After the run is complete, this cell loads the saved CSV and calculates the mean performance for each model type. This is the **final answer** to your research question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze the Results ---\n",
    "\n",
    "try:\n",
    "    # Load the results from the CSV\n",
    "    results_df = pd.read_csv(RESULTS_CSV_PATH)\n",
    "    \n",
    "    print(\"üìà K-Fold Results (Mean Performance):\")\n",
    "    \n",
    "    # We group by the 'model_name' and calculate the mean of all numeric metrics\n",
    "    mean_results = results_df.groupby('model_name').mean(numeric_only=True)\n",
    "    \n",
    "    # Tidy up the output\n",
    "    columns_to_show = ['accuracy', 'f1_score', 'precision', 'recall', 'train_time']\n",
    "    mean_results = mean_results[columns_to_show].sort_values(by='accuracy', ascending=False)\n",
    "    \n",
    "    print(mean_results.round(4))\n",
    "    \n",
    "    # Plot the main comparison\n",
    "    mean_results['accuracy'].plot(\n",
    "        kind='bar', \n",
    "        figsize=(12, 6), \n",
    "        title='Mean Accuracy Comparison (Higher is Better)',\n",
    "        ylabel='Mean Accuracy'\n",
    "    )\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training time\n",
    "    mean_results['train_time'].plot(\n",
    "        kind='bar', \n",
    "        figsize=(12, 6), \n",
    "        title='Mean Training Time Comparison (Lower is Better)',\n",
    "        ylabel='Mean Train Time (seconds)',\n",
    "        color='orange'\n",
    "    )\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Results file not found. Did you run the experiment in Cell 8?\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c0d300",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Visualization Helpers\n",
    "These are the functions to visualize the activations you saved in the `.pkl` file.\n",
    "\n",
    "* `visualize_input_image`: Shows the original input image.\n",
    "* `visualize_activation_maps_for_sample`: Shows feature maps for Conv/Pool layers for one image.\n",
    "* `visualize_dense_layer`: Shows the 1D activation vector for a Dense layer for one image.\n",
    "* `visualize_average_feature_maps`: Shows the *average* feature maps across the whole batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ff4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_input_image(loaded_data, image_index=0):\n",
    "    \"\"\"\n",
    "    Displays the original input image from the saved data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # data['inputs'] has shape (batch_size, H, W, C)\n",
    "        img = loaded_data['inputs'][image_index]\n",
    "        \n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Input Image (Sample {image_index})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting input image: {e}\")\n",
    "\n",
    "def visualize_activation_maps_for_sample(loaded_data, layer_name, image_index=0, max_features=16):\n",
    "    \"\"\"\n",
    "    Visualize the first few feature maps from a convolution or pooling layer\n",
    "    for a SINGLE image.\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing {layer_name} for image index {image_index}\")\n",
    "    \n",
    "    layer_outputs = loaded_data['activations']\n",
    "    if layer_name not in layer_outputs:\n",
    "        print(f\"Error: Layer '{layer_name}' not found. Available: {list(layer_outputs.keys())}\")\n",
    "        return\n",
    "\n",
    "    # shape: (H, W, channels)\n",
    "    feature_maps = layer_outputs[layer_name][image_index] \n",
    "    \n",
    "    if feature_maps.ndim != 3:\n",
    "        print(f\"Error: Layer {layer_name} is not a 3D (H, W, C) tensor. Skipping.\")\n",
    "        return\n",
    "        \n",
    "    num_features = min(feature_maps.shape[-1], max_features)\n",
    "    \n",
    "    cols = 4\n",
    "    rows = int(np.ceil(num_features / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        axes[i].imshow(feature_maps[:, :, i], cmap='viridis')\n",
    "        axes[i].set_title(f\"Filter {i+1}\")\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    for j in range(num_features, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        \n",
    "    plt.suptitle(f\"Activations for {layer_name} (Sample {image_index})\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_dense_layer(loaded_data, layer_name, image_index=0):\n",
    "    \"\"\"\n",
    "    Visualizes the activations of a 1D (Dense) layer as a heatmap.\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing {layer_name} for image index {image_index}\")\n",
    "    \n",
    "    layer_outputs = loaded_data['activations']\n",
    "    if layer_name not in layer_outputs:\n",
    "        print(f\"Error: Layer '{layer_name}' not found. Available: {list(layer_outputs.keys())}\")\n",
    "        return\n",
    "\n",
    "    # shape: (1, n_neurons) or (n_neurons,)\n",
    "    activations = layer_outputs[layer_name][image_index]\n",
    "    \n",
    "    # Ensure it's 2D for the heatmap\n",
    "    if activations.ndim == 1:\n",
    "        activations = np.expand_dims(activations, axis=0) # -> (1, n_neurons)\n",
    "        \n",
    "    if activations.ndim > 2 or (activations.shape[0] != 1 and activations.shape[1] != 1):\n",
    "        print(f\"Error: Layer {layer_name} is not a 1D vector. Skipping heatmap.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    sns.heatmap(activations, annot=True, fmt='.2f', cmap='viridis', cbar=False)\n",
    "    plt.title(f\"Activations for {layer_name} (Sample {image_index})\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.ylabel(\"Activation\")\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_average_feature_maps(loaded_data, layer_name, max_features=16):\n",
    "    \"\"\"\n",
    "    Calculates and visualizes the AVERAGE feature map across all samples\n",
    "    in the batch for a specific layer.\n",
    "    \"\"\"\n",
    "    print(f\"Visualizing AVERAGE {layer_name} across batch\")\n",
    "    \n",
    "    layer_outputs = loaded_data['activations']\n",
    "    if layer_name not in layer_outputs:\n",
    "        print(f\"Error: Layer '{layer_name}' not found. Available: {list(layer_outputs.keys())}\")\n",
    "        return\n",
    "\n",
    "    # activations shape: (batch_size, H, W, channels)\n",
    "    activations = layer_outputs[layer_name]\n",
    "    \n",
    "    if activations.ndim != 4:\n",
    "        print(f\"Error: Layer {layer_name} is not a 4D (N, H, W, C) tensor. Skipping.\")\n",
    "        return\n",
    "    \n",
    "    # Calculate the mean across the batch (axis=0)\n",
    "    mean_activations = np.mean(activations, axis=0) # shape: (H, W, channels)\n",
    "    \n",
    "    num_features = min(mean_activations.shape[-1], max_features)\n",
    "    \n",
    "    cols = 4\n",
    "    rows = int(np.ceil(num_features / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_features):\n",
    "        axes[i].imshow(mean_activations[:, :, i], cmap='viridis')\n",
    "        axes[i].set_title(f\"Filter {i+1} (Average)\")\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "    for j in range(num_features, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "        \n",
    "    plt.suptitle(f\"Average Activations for {layer_name} (Across Batch)\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a4f9a",
   "metadata": {},
   "source": [
    "### üëÅÔ∏è Run Visualizations\n",
    "\n",
    "Now that the experiment is complete, let's load the `.pkl` file saved from the *last* fold. This file contains a batch of input images and all the corresponding layer activations from the trained baseline CNN.\n",
    "\n",
    "We will step through the model, from input to output, to build an intuition for what it learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the Saved Data ---\n",
    "try:\n",
    "    with open(ACTIVATION_PKL_PATH, \"rb\") as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded activations from {ACTIVATION_PKL_PATH}\")\n",
    "    print(f\"Available layers: {list(loaded_data['activations'].keys())}\")\n",
    "    \n",
    "    # We will analyze the first image in the batch\n",
    "    IMG_TO_ANALYZE = 0\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Activation file not found. Did you run the experiment in Cell 8?\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad4428",
   "metadata": {},
   "source": [
    "#### Visualization 1: The Input Image\n",
    "\n",
    "First, let's look at the original image we will be tracing through the network. This gives us context for all the activation maps that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08378fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_input_image(loaded_data, image_index=IMG_TO_ANALYZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5032d0a",
   "metadata": {},
   "source": [
    "#### Visualization 2: Early Layer (`conv_1`)\n",
    "\n",
    "This is the output right after the **first** convolutional layer. We expect these filters to learn very simple, low-level features like edges, corners, and basic textures.\n",
    "\n",
    "* **Observe:** Do some filters activate on horizontal lines? Vertical lines? Bright spots? Dark spots? This is the model's first \"look\" at the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b902c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_activation_maps_for_sample(loaded_data, 'conv_1', image_index=IMG_TO_ANALYZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6a8bf",
   "metadata": {},
   "source": [
    "#### Visualization 3: Deeper Layer (`conv_2`)\n",
    "\n",
    "This is the output after the **second** convolutional layer. These filters have a larger receptive field (they \"see\" more of the original image) and combine the simple features from `conv_1` into more complex patterns.\n",
    "\n",
    "* **Observe:** Are these patterns more complex? Can you start to see filters that respond to \"furry\" textures, \"eye-like\" shapes, or \"ear-like\" curves? The features are becoming more abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_activation_maps_for_sample(loaded_data, 'conv_2', image_index=IMG_TO_ANALYZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6f87b",
   "metadata": {},
   "source": [
    "#### Visualization 4: Dense Layer (`dense_1`)\n",
    "\n",
    "After `conv_2`, the features are flattened into a long 1D vector and fed into the first Dense layer. This layer (`dense_1`) has 120 neurons.\n",
    "\n",
    "We can't view this as a 2D image, but we can use a **heatmap** to see which of the 120 neurons are firing (have a high activation value).\n",
    "\n",
    "* **Observe:** This vector is the \"feature representation\" that your Random Forest models `RF_from_dense_1` and `RF_from_dense_2` are using. A sparse activation pattern (mostly low values) is common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dense_layer(loaded_data, 'dense_1', image_index=IMG_TO_ANALYZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f3279",
   "metadata": {},
   "source": [
    "#### Visualization 5: Average Activations (What the Model *Generally* Looks For)\n",
    "\n",
    "The visualizations above were for a *single image*. What does the model look for *in general*?\n",
    "\n",
    "By averaging the activation maps across the entire batch, we can get a sense of the \"prototypical\" feature each filter is searching for.\n",
    "\n",
    "* **Observe:** The \"average\" feature maps might look blurrier, but they highlight the *most common* patterns that trigger each filter. This helps confirm if `conv_1` is truly a general edge detector and `conv_2` is a general pattern/texture detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65030d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- üßê Displaying Average Activations for conv_1 ---\")\n",
    "visualize_average_feature_maps(loaded_data, 'conv_1')\n",
    "\n",
    "print(\"\\n--- üßê Displaying Average Activations for conv_2 ---\")\n",
    "visualize_average_feature_maps(loaded_data, 'conv_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495d713",
   "metadata": {},
   "source": [
    "### üíæ Save Average Activations\n",
    "\n",
    "This cell fulfills the goal of saving the averaged tensor outputs. It loads the full activation pickle file, iterates through each layer, computes the mean activation across the batch, and saves these mean tensors into a new, smaller file.\n",
    "\n",
    "This file is ideal for future analysis or graphing, as it represents what the model *generally* \"sees\" at each layer for this batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0459d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Define the new path for the averaged activations\n",
    "AVG_ACTIVATION_PKL_PATH = os.path.join(RESULTS_DIR, \"last_fold_average_activations.pkl\")\n",
    "\n",
    "try:\n",
    "    # Load the full data from the main run\n",
    "    with open(ACTIVATION_PKL_PATH, \"rb\") as f:\n",
    "        loaded_data = pickle.load(f)\n",
    "    \n",
    "    all_activations = loaded_data['activations']\n",
    "    average_activations = {}\n",
    "    \n",
    "    print(f\"Calculating average activations...\")\n",
    "    \n",
    "    # Loop through each layer's activations\n",
    "    for layer_name, activations in all_activations.items():\n",
    "        # activations shape is (batch_size, ...)\n",
    "        # We calculate the mean along the batch axis (axis=0)\n",
    "        try:\n",
    "            mean_act = np.mean(activations, axis=0)\n",
    "            average_activations[layer_name] = mean_act\n",
    "            print(f\"  -> Calculated mean for {layer_name:20s} | New Shape: {mean_act.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  -> Error calculating mean for {layer_name}: {e}\")\n",
    "            \n",
    "    # Save the new dictionary of mean activations\n",
    "    with open(AVG_ACTIVATION_PKL_PATH, \"wb\") as f:\n",
    "        pickle.dump(average_activations, f)\n",
    "        \n",
    "    print(f\"\\n‚úÖ Successfully saved average activations to {AVG_ACTIVATION_PKL_PATH}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Activation file not found. Did you run the experiment in Cell 8?\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda3492",
   "metadata": {},
   "source": [
    "### üí° How to Use the Saved Averages\n",
    "\n",
    "In any future notebook or script, you can now easily load and use these averaged tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "AVG_PATH = \"./results/last_fold_average_activations.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(AVG_PATH, \"rb\") as f:\n",
    "        avg_activations = pickle.load(f)\n",
    "\n",
    "    print(\"Loaded average activations!\")\n",
    "    print(f\"Available layers: {list(avg_activations.keys())}\")\n",
    "\n",
    "    # Example: Get the average activation for the 'dense_1' layer\n",
    "    avg_dense_1 = avg_activations['dense_1']\n",
    "    print(f\"\\nAverage 'dense_1' shape: {avg_dense_1.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {AVG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c641ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
